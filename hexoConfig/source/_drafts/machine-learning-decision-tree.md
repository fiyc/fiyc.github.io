---
title: 机器学习实战 决策树
date: 2018-02-26 21:05:30
tags:
	- 机器学习
categories:
	- 机器学习
---

## 前言
> 你是否玩过二十个问题的游戏, 游戏的规则很简单: 参与游戏的一方在脑海里想某个事物, 其他参与者想他提问题, 只允许提20个问题, 问题的答案也只能用对或错回答. 问问题的人通过推断分解, 逐步缩小待猜测事物的范围. 决策树的工作原理与20个问题类似, 用户输入一系列数据, 然后给出游戏的答案.

<!-- more -->

## 决策树
决策树的工作方式可以参考下面的流程图

![决策树][1]

在上面的例子中, 我们可以看到数据的特征分别有这么几项: `发送邮件域名地址`, `单词包含‘曲棍球’`. 决策树在处理这些数据时, 根据特征做判断, 将结果指向不同的类别.  

### 决策树的特点
* 优点: 计算复杂度不高, 输出结果易于理解, 对中间值的缺失不敏感, 可以处理不相关特征数据.
* 缺点: 可能会产生过度匹配问题.
* 适用数据类型: 数值型和标称型

### 构造决策树
在构造决策树时, 我们首先要解决的第一个问题就是, 当前数据集上哪个特征在划分数据分类时起决定性作用. 随后我们使用这个特征作为决策点将数据划分. 子数据会分布在第一个决策点的所有分支上. 如果某个分之下的所有数据属于同一类型, 则当前分支数据不再需要拆分子类决策; 否则我们需要在这一子分支下寻找一个最佳特征, 重复上面的操作继续拆分.  

创建分支的伪代码函数`createBranch()`如下

```
检测数据集中的每个子项(特征)是否属于同一分类:
if so return 类标签;
else
	寻找划分数据集的最好特征
	划分数据集
	创建分支节点
		for 每个划分的子类
			调用函数createBranch并增加返回结果到分支节点中
	return 分支节点
```

### 决定性特征的选择
#### 香农熵

#### 代码实例



















[1]: http://www.fiyc.space/images/机器学习实战3-1.png "决策树"

